{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create Vaccine Datasets from Sheets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/salathegroup/multi-lang-vaccine-sentiment/blob/master/Create_Vaccine_Datasets_from_Sheets.ipynb",
      "authorship_tag": "ABX9TyNFX/Syxx506TOwS4/kfvqR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salathegroup/multi-lang-vaccine-sentiment/blob/master/Create_Vaccine_Datasets_from_Sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slkqrCYvU24K",
        "colab_type": "text"
      },
      "source": [
        "#Create Vaccine Datasets from Sheets\n",
        "Creates the vaccine datasets both for the annotated and the unannotated stuff stored in the Google Sheets.\n",
        "\n",
        "In the end it copies the training datasets to the Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZLs-U-tU0hm",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "2629c0bb-31cf-42b8-e1e9-2e29beb9cd51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "#@markdown ##Read Sheets\n",
        "!pip install pandas_ml\n",
        "\n",
        "import pandas as pd\n",
        "import pandas_ml as pdml\n",
        "import numpy as np\n",
        "import gspread\n",
        "import sys, os\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#Read the annotated data\n",
        "sh = gc.open('EPFL_vaccine_sentiment_3fold_agreed')\n",
        "worksheet = sh.worksheet(\"unique\")\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#Get it into pandas\n",
        "import pandas as pd\n",
        "annotated = pd.DataFrame.from_records(rows)\n",
        "annotated.columns = annotated.iloc[0]\n",
        "annotated = annotated.reindex(annotated.index.drop(0))\n",
        "annotated['a'] = \"a\"\n",
        "\n",
        "\n",
        "print(\"Successfully read the annotated data\")\n",
        "#Read the unannotated data\n",
        "sh = gc.open('EPFL unannotated tweets')\n",
        "worksheet = sh.worksheet(\"raw\")\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#Get it into pandas\n",
        "unannotated = pd.DataFrame.from_records(rows)\n",
        "unannotated.columns = unannotated.iloc[0]\n",
        "unannotated = unannotated.reindex(unannotated.index.drop(0))\n",
        "unannotated['a'] = \"a\"\n",
        "unannotated = unannotated[0:10000]\n",
        "\n",
        "print(\"Successfully read the unannotated data\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas_ml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/69/f63b234546e39558e8121980daaf7389e52554a608da50005f52dc14f53f/pandas_ml-0.6.1.tar.gz (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python2.7/dist-packages (from pandas_ml) (0.24.2)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (from pandas_ml) (1.1.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.19.0->pandas_ml) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas>=0.19.0->pandas_ml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.19.0->pandas_ml) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.0->pandas_ml) (1.12.0)\n",
            "Building wheels for collected packages: pandas-ml\n",
            "  Building wheel for pandas-ml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-ml: filename=pandas_ml-0.6.1-cp27-none-any.whl size=99434 sha256=e12adc6de78cbd92fd14a7aa1c527bdeb76a5157c97c35b00f9e96676c2c0068\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/a7/e0/6032cf33b7b780cdfc317752df74d6c0b2ed5a7031ab13f5e9\n",
            "Successfully built pandas-ml\n",
            "Installing collected packages: pandas-ml\n",
            "Successfully installed pandas-ml-0.6.1\n",
            "Successfully read the annotated data\n",
            "Successfully read the unannotated data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZegQq60XxCD",
        "colab_type": "code",
        "outputId": "e79a96e2-9a7d-4730-ee38-7dbd6fd9f440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# #@markdown ##Create and Copy Data Files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#annotated data\n",
        "#Split into 60% train - 20% validation/development - 20% test\n",
        "train   = annotated.loc[annotated[\"group\"] == \"train\"]\n",
        "train_small = train.sample(n=1000, random_state=42)\n",
        "\n",
        "dev   = annotated.loc[annotated[\"group\"] == \"dev\"]\n",
        "test   = annotated.loc[annotated[\"group\"] == \"test\"]\n",
        "\n",
        "languages = [\"cb-annot-en\",\"cb-annot-en-fr\",\"cb-annot-en-de\",\"cb-annot-en-es\",\"cb-annot-en-pt\"]\n",
        "\n",
        "if not os.path.exists('annotated'):\n",
        "    os.makedirs('annotated')\n",
        "\n",
        "if not os.path.exists('cb-annot-en-de-fr-es'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es')\n",
        "\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-sm'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-sm')\n",
        "\n",
        "\n",
        "for lang in languages:\n",
        "  #Save annotated (large)\n",
        "  if not os.path.exists(lang):\n",
        "    os.makedirs(lang)\n",
        "  \n",
        "  with open('/content/'+lang+\"/train.tsv\", 'w') as f:\n",
        "    f.write(train.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+\"/dev.tsv\", 'w') as f:\n",
        "    f.write(dev.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+\"/test.tsv\", 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+\"/annotated_test.tsv\", 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  #Save annotated small\n",
        "  if not os.path.exists(lang+'-sm'):\n",
        "      os.makedirs(lang+'-sm')\n",
        "    \n",
        "  with open('/content/'+lang+'-sm/train.tsv', 'w') as f:\n",
        "    f.write(train_small.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+'-sm/dev.tsv', 'w') as f:\n",
        "    f.write(dev.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+'-sm/test.tsv', 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+'-sm/annotated_test.tsv', 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "#Save annotated all\n",
        "en = train[[\"id\",\"label\",\"a\",\"cb-annot-en\"]]\n",
        "en.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "pt = train[[\"id\",\"label\",\"a\",\"cb-annot-en-pt\"]]\n",
        "pt.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "fr = train[[\"id\",\"label\",\"a\",\"cb-annot-en-fr\"]]\n",
        "fr.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "de = train[[\"id\",\"label\",\"a\",\"cb-annot-en-de\"]]\n",
        "de.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "es = train[[\"id\",\"label\",\"a\",\"cb-annot-en-es\"]]\n",
        "es.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "\n",
        "all_lang = pd.concat([en,pt,fr,de,es], join=\"inner\")\n",
        "all_lang = all_lang.sample(n=len(all_lang), random_state=42)\n",
        "all_lang.reset_index(inplace=True)  \n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es/train.tsv', 'w') as f:\n",
        "  f.write(all_lang.to_csv(columns=[\"id\", \"label\", \"a\", \"text\"], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "\n",
        "#Save annotated all small\n",
        "en_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en\"]]\n",
        "en_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "pt_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-pt\"]]\n",
        "pt_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "fr_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-fr\"]]\n",
        "fr_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "de_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-de\"]]\n",
        "de_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "es_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-es\"]]\n",
        "es_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "\n",
        "all_lang_small = pd.concat([en_small,pt_small,fr_small,de_small,es_small], join=\"inner\")\n",
        "all_lang_small = all_lang.sample(n=len(all_lang_small), random_state=42)\n",
        "all_lang_small.reset_index(inplace=True)  \n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-sm/train.tsv', 'w') as f:\n",
        "  f.write(all_lang_small.to_csv(columns=['id', 'label', 'a', \"text\"], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "\n",
        "#unannotated data\n",
        "languages = [\"cb-en\",\"cb-en-fr\",\"cb-en-de\",\"cb-en-es\",\"cb-en-pt\"]\n",
        "\n",
        "if not os.path.exists('cb-unannotated'):\n",
        "    os.makedirs('cb-unannotated')\n",
        "\n",
        "for lang in languages:  \n",
        "  with open('/content/cb-unannotated/'+lang+\".tsv\", 'w') as f:\n",
        "    f.write(unannotated.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "print(\"Created the data files locally\")\n",
        "positive = all_lang[all_lang['label'] == 'positive']\n",
        "negative = all_lang[all_lang['label'] == 'negative']\n",
        "neutral = all_lang[all_lang['label'] == 'neutral']\n",
        "\n",
        "\n",
        "#Balancing the datasets\n",
        "#Oversampled data\n",
        "positive = all_lang[all_lang['label'] == 'positive']\n",
        "negative = all_lang[all_lang['label'] == 'negative']\n",
        "neutral = all_lang[all_lang['label'] == 'neutral']\n",
        "\n",
        "positive_os = positive.sample(n=len(neutral), random_state=42, replace=True)\n",
        "negative_os = negative.sample(n=len(neutral), random_state=42, replace=True)\n",
        "neutral_os = neutral\n",
        "all_os = pd.concat([positive_os, negative_os, neutral_os], join=\"inner\")\n",
        "all_os = all_os.sample(n=len(all_os), random_state=42)\n",
        "all_os.reset_index(inplace=True) \n",
        "\n",
        "#Undersampled data\n",
        "positive_us = positive.sample(n=len(negative), random_state=42)\n",
        "negative_us = negative\n",
        "neutral_us = neutral.sample(n=len(negative), random_state=42)\n",
        "all_us = pd.concat([positive_us, negative_us, neutral_us], join=\"inner\")\n",
        "all_us = all_us.sample(n=len(all_us), random_state=42)\n",
        "all_us.reset_index(inplace=True) \n",
        "\n",
        "#Writing balanced data\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-os'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-os')\n",
        "\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-us'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-us')\n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-os/train.tsv', 'w') as f:\n",
        "  f.write(all_os.to_csv(columns=['id', 'label', 'a', lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-us/train.tsv', 'w') as f:\n",
        "  f.write(all_us.to_csv(columns=['id', 'label', 'a', lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "\n",
        "#Copy everything to the bucket\n",
        "##!gsutil -m cp -r cb-*/ gs://perepublic/EPFL_multilang/data/\n",
        "\n",
        "#print(\"Copied the data to the bucket\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created the data files locally\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}