{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create Vaccine Datasets from Sheets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/salathegroup/multi-lang-vaccine-sentiment/blob/master/Create_Vaccine_Datasets_from_Sheets.ipynb",
      "authorship_tag": "ABX9TyOV1o5luzEB48RgXVKD2n5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salathegroup/multi-lang-vaccine-sentiment/blob/master/Create_Vaccine_Datasets_from_Sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slkqrCYvU24K",
        "colab_type": "text"
      },
      "source": [
        "#Create Vaccine Datasets from Sheets\n",
        "Creates the vaccine datasets both for the annotated and the unannotated stuff stored in the Google Sheets.\n",
        "\n",
        "In the end it copies the training datasets to the Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZLs-U-tU0hm",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "67386093-b5af-4b45-8c47-24525dc32b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#@markdown ##Read Sheets\n",
        "!pip install pandas_ml\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gspread\n",
        "import sys, os\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#Read the annotated data\n",
        "sh = gc.open('EPFL_vaccine_sentiment_3fold_agreed')\n",
        "worksheet = sh.worksheet(\"unique\")\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#Get it into pandas\n",
        "import pandas as pd\n",
        "annotated = pd.DataFrame.from_records(rows)\n",
        "annotated.columns = annotated.iloc[0]\n",
        "annotated = annotated.reindex(annotated.index.drop(0))\n",
        "annotated['a'] = \"a\"\n",
        "\n",
        "\n",
        "print(\"Successfully read the annotated data\")\n",
        "#Read the unannotated data\n",
        "sh = gc.open('EPFL unannotated tweets')\n",
        "worksheet = sh.worksheet(\"raw\")\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#Get it into pandas\n",
        "unannotated = pd.DataFrame.from_records(rows)\n",
        "unannotated.columns = unannotated.iloc[0]\n",
        "unannotated = unannotated.reindex(unannotated.index.drop(0))\n",
        "unannotated['a'] = \"a\"\n",
        "unannotated = unannotated[0:10000]\n",
        "\n",
        "print(\"Successfully read the unannotated data\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_ml in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.6/dist-packages (from pandas_ml) (1.1.8)\n",
            "Requirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from pandas_ml) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas_ml) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas_ml) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas_ml) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.19.0->pandas_ml) (1.12.0)\n",
            "Successfully read the annotated data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZegQq60XxCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #@markdown ##Create and Copy Data Files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!rm -rf /content/annotate*\n",
        "!rm -rf /content/cb*\n",
        "\n",
        "\n",
        "#annotated data\n",
        "#Split into 60% train - 20% validation/development - 20% test\n",
        "train   = annotated.loc[annotated[\"group\"] == \"train\"]\n",
        "train_small = train.sample(n=1000, random_state=42)\n",
        "\n",
        "dev   = annotated.loc[annotated[\"group\"] == \"dev\"]\n",
        "test   = annotated.loc[annotated[\"group\"] == \"test\"]\n",
        "\n",
        "languages = [\"cb-annot-en\",\"cb-annot-en-fr\",\"cb-annot-en-de\",\"cb-annot-en-es\",\"cb-annot-en-pt\"]\n",
        "\n",
        "if not os.path.exists('annotated'):\n",
        "    os.makedirs('annotated')\n",
        "\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-pt'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-pt')\n",
        "\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-pt-sm'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-pt-sm')\n",
        "\n",
        "\n",
        "for lang in languages:\n",
        "  #Save annotated (large)\n",
        "  if not os.path.exists(lang):\n",
        "    os.makedirs(lang)\n",
        "  \n",
        "  with open('/content/'+lang+\"/train.tsv\", 'w') as f:\n",
        "    f.write(train.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+\"/dev.tsv\", 'w') as f:\n",
        "    f.write(dev.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+\"/test.tsv\", 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+\"/annotated_test.tsv\", 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  #Save annotated small\n",
        "  if not os.path.exists(lang+'-sm'):\n",
        "      os.makedirs(lang+'-sm')\n",
        "    \n",
        "  with open('/content/'+lang+'-sm/train.tsv', 'w') as f:\n",
        "    f.write(train_small.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+'-sm/dev.tsv', 'w') as f:\n",
        "    f.write(dev.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+'-sm/test.tsv', 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "  with open('/content/'+lang+'-sm/annotated_test.tsv', 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "#Save annotated all\n",
        "en = train[[\"id\",\"label\",\"a\",\"cb-annot-en\"]]\n",
        "en.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "pt = train[[\"id\",\"label\",\"a\",\"cb-annot-en-pt\"]]\n",
        "pt.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "fr = train[[\"id\",\"label\",\"a\",\"cb-annot-en-fr\"]]\n",
        "fr.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "de = train[[\"id\",\"label\",\"a\",\"cb-annot-en-de\"]]\n",
        "de.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "es = train[[\"id\",\"label\",\"a\",\"cb-annot-en-es\"]]\n",
        "es.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "\n",
        "all_lang = pd.concat([en,pt,fr,de,es], join=\"inner\")\n",
        "all_lang = all_lang.sample(n=len(all_lang), random_state=42)\n",
        "all_lang.reset_index(inplace=True)  \n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-pt/train.tsv', 'w') as f:\n",
        "  f.write(all_lang.to_csv(columns=[\"id\", \"label\", \"a\", \"text\"], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "\n",
        "#Save annotated all small\n",
        "en_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en\"]]\n",
        "en_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "pt_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-pt\"]]\n",
        "pt_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "fr_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-fr\"]]\n",
        "fr_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "de_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-de\"]]\n",
        "de_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "es_small = train_small[[\"id\",\"label\",\"a\",\"cb-annot-en-es\"]]\n",
        "es_small.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "\n",
        "all_lang_small = pd.concat([en_small,pt_small,fr_small,de_small,es_small], join=\"inner\")\n",
        "all_lang_small = all_lang.sample(n=len(all_lang_small), random_state=42)\n",
        "all_lang_small.reset_index(inplace=True)  \n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-pt-sm/train.tsv', 'w') as f:\n",
        "  f.write(all_lang_small.to_csv(columns=['id', 'label', 'a', \"text\"], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "\n",
        "#unannotated data\n",
        "languages = [\"cb-en\",\"cb-en-fr\",\"cb-en-de\",\"cb-en-es\",\"cb-en-pt\"]\n",
        "\n",
        "if not os.path.exists('cb-unannotated'):\n",
        "    os.makedirs('cb-unannotated')\n",
        "\n",
        "for lang in languages:  \n",
        "  with open('/content/cb-unannotated/'+lang+\".tsv\", 'w') as f:\n",
        "    f.write(unannotated.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t',encoding = 'utf-8'))\n",
        "\n",
        "print(\"Created the data files locally\")\n",
        "positive = all_lang[all_lang['label'] == 'positive']\n",
        "negative = all_lang[all_lang['label'] == 'negative']\n",
        "neutral = all_lang[all_lang['label'] == 'neutral']\n",
        "\n",
        "\n",
        "#Balancing the datasets\n",
        "#Oversampled data\n",
        "positive = all_lang[all_lang['label'] == 'positive']\n",
        "negative = all_lang[all_lang['label'] == 'negative']\n",
        "neutral = all_lang[all_lang['label'] == 'neutral']\n",
        "\n",
        "positive_os = positive.sample(n=len(neutral), random_state=42, replace=True)\n",
        "negative_os = negative.sample(n=len(neutral), random_state=42, replace=True)\n",
        "neutral_os = neutral\n",
        "all_os = pd.concat([positive_os, negative_os, neutral_os], join=\"inner\")\n",
        "all_os = all_os.sample(n=len(all_os), random_state=42)\n",
        "all_os.reset_index(inplace=True) \n",
        "\n",
        "#Undersampled data\n",
        "#To do this correctly we need to start with the \"flat\" dataset with individual languages instead of the concatenated set\n",
        "#This will prevent the undersampled data to appear in other languages\n",
        "positive_flat = train[train['label'] == 'positive']\n",
        "negative_flat = train[train['label'] == 'negative']\n",
        "neutral_flat = train[train['label'] == 'neutral']\n",
        "\n",
        "positive_us = positive_flat.sample(n=len(negative_flat), random_state=42)\n",
        "negative_us = negative_flat\n",
        "neutral_us = neutral_flat.sample(n=len(negative_flat), random_state=42)\n",
        "\n",
        "all_lang_us = pd.concat([positive_us,negative_us,neutral_us], join=\"inner\")\n",
        "\n",
        "#Concatenate all the languages\n",
        "en_us = all_lang_us[[\"id\",\"label\",\"a\",\"cb-annot-en\"]]\n",
        "en_us.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "pt_us = all_lang_us[[\"id\",\"label\",\"a\",\"cb-annot-en-pt\"]]\n",
        "pt_us.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "fr_us = all_lang_us[[\"id\",\"label\",\"a\",\"cb-annot-en-fr\"]]\n",
        "fr_us.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "de_us = all_lang_us[[\"id\",\"label\",\"a\",\"cb-annot-en-de\"]]\n",
        "de_us.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "es_us = all_lang_us[[\"id\",\"label\",\"a\",\"cb-annot-en-es\"]]\n",
        "es_us.columns = [\"id\",\"label\",\"a\",\"text\"]\n",
        "\n",
        "all_us = pd.concat([en_us,pt_us,fr_us,de_us,es_us], join=\"inner\")\n",
        "all_us = all_us.sample(n=len(all_us), random_state=42)\n",
        "all_us.reset_index(inplace=True) \n",
        "\n",
        "\n",
        "#Writing balanced data\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-pt-os'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-pt-os')\n",
        "\n",
        "if not os.path.exists('cb-annot-en-de-fr-es-pt-us'):\n",
        "    os.makedirs('cb-annot-en-de-fr-es-pt-us')\n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-pt-os/train.tsv', 'w') as f:\n",
        "  f.write(all_os.to_csv(columns=['id', 'label', 'a', 'text'], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "with open('/content/cb-annot-en-de-fr-es-pt-us/train.tsv', 'w') as f:\n",
        "  f.write(all_us.to_csv(columns=['id', 'label', 'a', 'text'], header=False, index=False, sep='\\t',encoding = 'utf-8'))  \n",
        "\n",
        "\n",
        "#Copy everything to the bucket\n",
        "!gsutil -m cp -r cb-*/ gs://perepublic/EPFL_multilang/data/\n",
        "\n",
        "print(\"Copied the data to the bucket\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}