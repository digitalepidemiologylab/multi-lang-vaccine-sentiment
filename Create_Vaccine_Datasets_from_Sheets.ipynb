{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create Vaccine Datasets from Sheets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9EI67QkDKWPasyrs5G7wz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salathegroup/vaccine-multi-lang/blob/master/Create_Vaccine_Datasets_from_Sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slkqrCYvU24K",
        "colab_type": "text"
      },
      "source": [
        "#Create Vaccine Datasets from Sheets\n",
        "Creates the vaccine datasets both for the annotated and the unannotated stuff stored in the Google Sheets.\n",
        "\n",
        "In the end it copies the training datasets to the Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZLs-U-tU0hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "cellView": "both",
        "outputId": "a529e2dc-3c66-41e2-e7ac-6d47451d7889"
      },
      "source": [
        "#@markdown ##Read Sheets\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gspread\n",
        "import sys, os\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#Read the annotated data\n",
        "sh = gc.open('EPFL_vaccine_sentiment_3fold_agreed')\n",
        "worksheet = sh.worksheet(\"unique\")\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#Get it into pandas\n",
        "import pandas as pd\n",
        "annotated = pd.DataFrame.from_records(rows)\n",
        "annotated.columns = annotated.iloc[0]\n",
        "annotated = annotated.reindex(annotated.index.drop(0))\n",
        "annotated['a'] = \"a\"\n",
        "\n",
        "\n",
        "print(\"Successfully read the annotated data\")\n",
        "#Read the unannotated data\n",
        "sh = gc.open('EPFL unannotated tweets')\n",
        "worksheet = sh.worksheet(\"raw\")\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#Get it into pandas\n",
        "unannotated = pd.DataFrame.from_records(rows)\n",
        "unannotated.columns = unannotated.iloc[0]\n",
        "unannotated = unannotated.reindex(unannotated.index.drop(0))\n",
        "unannotated['a'] = \"a\"\n",
        "unannotated = unannotated[0:10000]\n",
        "\n",
        "print(\"Successfully read the unannotated data\")\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully read the annotated data\n",
            "Successfully read the unannotated data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZegQq60XxCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#annotated data\n",
        "#Split into 60% train - 20% validation/development - 20% test\n",
        "train   = annotated.loc[annotated[\"group\"] == \"train\"]\n",
        "train_small = train.sample(n=1000, random_state=42)\n",
        "\n",
        "dev   = annotated.loc[annotated[\"group\"] == \"dev\"]\n",
        "test   = annotated.loc[annotated[\"group\"] == \"test\"]\n",
        "\n",
        "languages = [\"en\",\"fr\",\"de\",\"es\",\"pt\"]\n",
        "\n",
        "if not os.path.exists('annotated'):\n",
        "    os.makedirs('annotated')\n",
        "\n",
        "for lang in languages:\n",
        "  #Save annotated (large)\n",
        "  if not os.path.exists('annotated/'+lang):\n",
        "    os.makedirs('annotated/'+lang)\n",
        "  \n",
        "  with open('/content/annotated/'+lang+\"/train.tsv\", 'w') as f:\n",
        "    f.write(train.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "  with open('/content/annotated/'+lang+\"/dev.tsv\", 'w') as f:\n",
        "    f.write(dev.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "  with open('/content/annotated/'+lang+\"/test.tsv\", 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "  #Save annotated small\n",
        "  if not os.path.exists('annotated_small/'+lang):\n",
        "      os.makedirs('annotated_small/'+lang)\n",
        "    \n",
        "  with open('/content/annotated_small/'+lang+\"/train.tsv\", 'w') as f:\n",
        "    f.write(train_small.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "  with open('/content/annotated_small/'+lang+\"/dev.tsv\", 'w') as f:\n",
        "    f.write(dev.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "  with open('/content/annotated_small/'+lang+\"/test.tsv\", 'w') as f:\n",
        "    f.write(test.to_csv(columns=[\"id\", \"label\", \"a\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "#unannotated data\n",
        "languages = [\"en\",\"fr\",\"de\",\"es\"]\n",
        "\n",
        "if not os.path.exists('unannotated'):\n",
        "    os.makedirs('unannotated')\n",
        "\n",
        "for lang in languages:  \n",
        "  with open('/content/unannotated/'+lang+\".tsv\", 'w') as f:\n",
        "    f.write(train.to_csv(columns=[\"id\", lang], header=False, index=False, sep='\\t'))\n",
        "\n",
        "\n",
        "#Copy everything to the bucket\n",
        "!gsutil -m cp -r *annotated*/ gs://perepublic/EPFL_multilang/\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}