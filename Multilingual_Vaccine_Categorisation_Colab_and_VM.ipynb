{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilingual Vaccine Categorisation Colab and VM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salathegroup/multi-lang-vaccine-sentiment/blob/master/Multilingual_Vaccine_Categorisation_Colab_and_VM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDOZl0YzcyrB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Multilingual Vaccine Categorisation - Colab and VM\n",
        "Performing vaccine stance fintetuning/categorisation training on various multilingual dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Le7qQsAWGU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "RUN_IN_COLAB = True  #@param {type:\"boolean\"}\n",
        "USE_TPU = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if not RUN_IN_COLAB:\n",
        "  import sys, getopt\n",
        "  if len(sys.argv) !=3:\n",
        "    print(\"Error. Provide an ip-address for the TPU and a unique username \")\n",
        "    sys.exit()\n",
        "\n",
        "  print(\"IP set to: \"+str(sys.argv[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP7Mo51ARJJ6",
        "colab_type": "text"
      },
      "source": [
        "# Step 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p7jRmgcP_ws",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "4686134c-3405-4f77-b592-7982e2e09257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@markdown ##Autenticate, Import Libraries and Copy Data Files\n",
        "\n",
        "\n",
        "#import modules\n",
        "import sys, os, json, csv, datetime, pprint\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Progbar\n",
        "import sklearn.metrics\n",
        "\n",
        "#Authenticate\n",
        "auth.authenticate_user()\n",
        "\n",
        "##Copy all the training data locally\n",
        "if not os.path.exists('data'):\n",
        "  os.makedirs('data')\n",
        "  !gsutil -m cp -r gs://perepublic/EPFL_multilang/data/ /content/\n",
        "else:\n",
        "  print('All training files has already been copied to /content/data')\n",
        "\n",
        "#Clone Bert\n",
        "if not os.path.exists('bert_repo'):  \n",
        "  !test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "else:\n",
        "  print('The Bert repository has already been cloned')\n",
        "\n",
        "if not '/content/bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "  sys.path += ['/content/bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "\n",
        "if RUN_IN_COLAB:\n",
        "  #Mount Google Drive   \n",
        "  if not os.path.exists('/content/GDrive/'):\n",
        "    print('Mounting Google Drive')\n",
        "    drive.mount('/content/GDrive', force_remount=False)\n",
        "  else:\n",
        "    print('Your Google Drive is already mounted at /content/GDrive')\n",
        "\n",
        "if USE_TPU:\n",
        "  if RUN_IN_COLAB:\n",
        "    #Enable TPUs\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "    TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    \n",
        "  else:\n",
        "    TPU_ADDRESS = 'grpc://' + str(sys.argv[1]) + ':8470'\n",
        "  \n",
        "  print('TPU address is', TPU_ADDRESS)\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(session.list_devices())\n",
        "\n",
        "  \n",
        "  # Upload credentials to TPU for all future sessions on this TPU.\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "\n",
        "\n",
        "#Define some custom functions\n",
        "class vaccineStanceProcessor(run_classifier.DataProcessor):\n",
        "  \"\"\"Processor for the NoRec data set.\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir, 'train.tsv')), 'train')\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir, 'dev.tsv')), 'dev')\n",
        "\n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir, 'test.tsv')), 'test')\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return ['positive','neutral','negative']\n",
        "\n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      # Only the test set has a header\n",
        "      if set_type == 'test' and i == 0:\n",
        "        continue\n",
        "      guid = '%s-%s' % (set_type, i)\n",
        "      if set_type == 'test':\n",
        "        text_a = tokenization.convert_to_unicode(line[3])\n",
        "        #Set a dummy value. This is not used\n",
        "        label = 'positive'\n",
        "      else:\n",
        "        text_a = tokenization.convert_to_unicode(line[3])\n",
        "        label = tokenization.convert_to_unicode(line[1])\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "    return examples\n",
        "\n",
        "# Train the model\n",
        "def model_train(estimator):\n",
        "  # Time to train another model - Clean the output directory.\n",
        "  !gsutil rm -r $TEMP_OUTPUT_DIR\n",
        "\n",
        "  # Force TF Hub writes to the GS bucket we provide.\n",
        "  os.environ['TFHUB_CACHE_DIR'] = TEMP_OUTPUT_DIR\n",
        "  \n",
        "  print('Fine tuning BERT base model normally takes a few minutes. Please wait...')\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train_examples)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  print('  Train steps = {}'.format(num_train_steps))\n",
        "  print('  Epochs = {}'.format(NUM_TRAIN_EPOCHS))\n",
        "  \n",
        "  tf.logging.info('  Num steps = %d', num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
        "\n",
        "# Evaluate the model.\n",
        "def model_eval(estimator):\n",
        "  eval_examples = processor.get_dev_examples(EVAL_ANNOT_DATASET_DIR)\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('Num examples = {}'.format(len(eval_examples)))\n",
        "  print('Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(TEMP_OUTPUT_DIR, 'eval_results.txt')\n",
        "  with tf.gfile.GFile(output_eval_file, 'w') as writer:\n",
        "    print('***** Eval results *****')\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write('%s = %s\\n' % (key, str(result[key])))\n",
        "  predictions = estimator.predict(eval_input_fn)\n",
        "  y_pred = [np.argmax(p['probabilities']) for p in predictions]\n",
        "  y_true = [e.label_id for e in eval_features]\n",
        "  label_mapping = dict(zip(range(len(label_list)), label_list))\n",
        "  scores = performance_metrics(y_true, y_pred, label_mapping=label_mapping)\n",
        "  print('Final scores:')\n",
        "  print(scores)\n",
        "\n",
        "  # Write log to Training Log File\n",
        "  data = {'Experiment_Name': EXP_NAME,'Date': format(datetime.datetime.now()),'User': USERNAME, 'Model': BERT_MODEL_NAME, 'Train_Annot_Dataset': TRAIN_ANNOT_DATASET,'Eval_Annot_Dataset': EVAL_ANNOT_DATASET, 'Num_Train_Epochs': NUM_TRAIN_EPOCHS,'Learning_Rate': LEARNING_RATE, 'Max_Seq_Length': MAX_SEQ_LENGTH, 'Eval_Loss': result['eval_loss'],'Loss': result['loss'], 'Comment': COMMENT, **scores}\n",
        "  datafields = sorted(data.keys())\n",
        "\n",
        "  if not os.path.isfile(TRAINING_LOG_FILE):\n",
        "    with open(TRAINING_LOG_FILE, mode='w') as output:\n",
        "      output_writer = csv.DictWriter(output, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, fieldnames=datafields)\n",
        "      output_writer.writeheader()\n",
        "  with open(TRAINING_LOG_FILE, mode='a+') as output:\n",
        "    output_writer = csv.DictWriter(output, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL, fieldnames=datafields)\n",
        "    output_writer.writerow(data)\n",
        "    print(\"Wrote log to csv-file\")\n",
        "\n",
        "def performance_metrics(y_true, y_pred, metrics=None, averaging=None, label_mapping=None):\n",
        "    \"\"\"\n",
        "    Compute performance metrics\n",
        "    \"\"\"\n",
        "    def _compute_performance_metric(scoring_function, m, y_true, y_pred):\n",
        "        for av in averaging:\n",
        "            if av is None:\n",
        "                metrics_by_class = scoring_function(y_true, y_pred, average=av, labels=labels)\n",
        "                for i, class_metric in enumerate(metrics_by_class):\n",
        "                    if label_mapping is None:\n",
        "                        label_name = labels[i]\n",
        "                    else:\n",
        "                        label_name = label_mapping[labels[i]]\n",
        "                    scores[m + '_' + str(label_name)] = class_metric\n",
        "            else:\n",
        "                scores[m + '_' + av] = scoring_function(y_true, y_pred, average=av, labels=labels)\n",
        "    if averaging is None:\n",
        "        averaging = ['micro', 'macro', 'weighted', None]\n",
        "    if metrics is None:\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "    scores = {}\n",
        "    if label_mapping is None:\n",
        "        # infer labels from data\n",
        "        labels = sorted(list(set(y_true + y_pred)))\n",
        "    else:\n",
        "        labels = sorted(list(label_mapping.keys()))\n",
        "    if len(labels) <= 2:\n",
        "        # binary classification\n",
        "        averaging += ['binary']\n",
        "    for m in metrics:\n",
        "        if m == 'accuracy':\n",
        "            scores[m] = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "        elif m == 'precision':\n",
        "            _compute_performance_metric(sklearn.metrics.precision_score, m, y_true, y_pred)\n",
        "        elif m == 'recall':\n",
        "            _compute_performance_metric(sklearn.metrics.recall_score, m, y_true, y_pred)\n",
        "        elif m == 'f1':\n",
        "            _compute_performance_metric(sklearn.metrics.f1_score, m, y_true, y_pred)\n",
        "    return scores\n",
        "\n",
        "def model_init():\n",
        "  #Initiation\n",
        "  model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(os.path.join(BERT_MODEL_DIR,'bert_config.json')),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=BERT_MODEL_FILE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=USE_TPU,\n",
        "    use_one_hot_embeddings=True\n",
        "  )\n",
        "\n",
        "  estimator_from_checkpoints = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=get_run_config(TEMP_OUTPUT_DIR),\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=PREDICT_BATCH_SIZE,\n",
        "  )\n",
        "\n",
        "  return estimator_from_checkpoints\n",
        "\n",
        "def model_predict(estimator):\n",
        "  # Make predictions on a subset of eval examples\n",
        "  prediction_examples = processor.get_dev_examples(TASK_DATA_DIR)[:PREDICT_BATCH_SIZE]\n",
        "  input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "\n",
        "  for example, prediction in zip(prediction_examples, predictions):\n",
        "    print('text_a: %s\\nlabel:%s\\nprediction:%s\\n' % (example.text_a, str(example.label), prediction['probabilities']))\n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de-sm/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de-fr-es/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de-sm/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de-sm/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de-fr-es-sm/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de-sm/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-de/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es-sm/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es-sm/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es-sm/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es-sm/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-es/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr-sm/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr-sm/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr-sm/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr-sm/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-fr/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt-sm/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt-sm/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt-sm/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt-sm/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-pt/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-sm/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-sm/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-sm/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en-sm/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en/annotated_test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en/dev.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en/test.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-annot-en/train.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-unannotated/cb-en-de.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-unannotated/cb-en-es.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-unannotated/cb-en-fr.tsv...\n",
            "Copying gs://perepublic/EPFL_multilang/data/cb-unannotated/cb-en.tsv...\n",
            "/ [46/46 files][ 19.9 MiB/ 19.9 MiB] 100% Done                                  \n",
            "Operation completed over 46 objects/19.9 MiB.                                    \n",
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Total 336 (delta 0), reused 0 (delta 0), pack-reused 336\u001b[K\n",
            "Receiving objects: 100% (336/336), 290.62 KiB | 3.77 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n",
            "WARNING:tensorflow:From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Mounting Google Drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/GDrive\n",
            "TPU address is grpc://10.32.80.50:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 9056964511981067859),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12578579154270239786),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 16419117274771192929),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 15293778589907173645),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11363403226778945391),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16541929340818009114),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13779756758022404792),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3598447114234383465),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9756882873676041476),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4215090844268192741),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 18231005442920781020)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY-Qi72ARQ5t",
        "colab_type": "text"
      },
      "source": [
        "# Step 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uARjMh9mCcUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown ##Initiate Model and Parameters\n",
        "#@markdown Username and Comment are only used in temporal folders and in the train log file\n",
        "\n",
        "#General Files and Settings\n",
        "USERNAME = \"pere\" #@param {type:\"string\"}\n",
        "#@markdown <br />\n",
        "\n",
        "COMMENT = 'My test'#@param {type:\"string\"}\n",
        "EXP_NAME = 'default-exp-name'\n",
        "#@markdown <br />\n",
        "BERT_MODEL_DIR = 'gs://perepublic/multi_cased_L-12_H-768_A-12/'#@param {type:\"string\"}\n",
        "BERT_MODEL_NAME = 'bert_model.ckpt.index'#@param {type:\"string\"}\n",
        "TEMP_OUTPUT_DIR = 'gs://perepublic/finetuned_models/' #@param {type:\"string\"}\n",
        "TRAINING_LOG_FILE = '/content/GDrive/My Drive/multi-lang-vaccine-sentiment/trainlog.csv'#@param {type:\"string\"}\n",
        "#@markdown <br />\n",
        "#@markdown Only relevant if you should run the train/eval example. Not used in experiments\n",
        "\n",
        "TRAIN_ANNOT_DATASET = 'cb-annot-en' #@param ['cb-annot-en','cb-annot-en-de','cb-annot-en-es','cb-annot-en-fr','cb-annot-en-pt','cb-annot-en-sm','cb-annot-en-de-sm','cb-annot-en-es-sm','cb-annot-en-fr-sm','cb-annot-en-pt-sm']\n",
        "EVAL_ANNOT_DATASET = 'cb-annot-en' #@param ['cb-annot-en','cb-annot-en-de','cb-annot-en-es','cb-annot-en-fr','cb-annot-en-pt','cb-annot-en-sm','cb-annot-en-de-sm','cb-annot-en-es-sm','cb-annot-en-fr-sm','cb-annot-en-pt-sm']\n",
        "\n",
        "#Complete some paths\n",
        "BERT_MODEL_FILE = os.path.join(BERT_MODEL_DIR,BERT_MODEL_NAME)\n",
        "\n",
        "\n",
        "TRAIN_ANNOT_DATASET_DIR = os.path.join('/content/data',TRAIN_ANNOT_DATASET)\n",
        "EVAL_ANNOT_DATASET_DIR = os.path.join('/content/data',EVAL_ANNOT_DATASET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWrLfVHeXkf-",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "fd55d7e2-9652-4b66-abe9-c1f730b6885b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#Model Finetuning Hyperparameters\n",
        "NUM_TRAIN_EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "MAX_SEQ_LENGTH = 128\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 64\n",
        "WARMUP_PROPORTION = 0.1\n",
        "\n",
        "#Other Config\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 500\n",
        "USE_TPU = True\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "LOWER_CASED = False\n",
        "\n",
        "#Do checks to see if all necessary files exists\n",
        "if not tf.gfile.Exists(BERT_MODEL_DIR):\n",
        "  print('Can not access the Bert model directory')\n",
        "  sys.exit('Stopping execution!')\n",
        "\n",
        "if not tf.gfile.Exists(TRAIN_ANNOT_DATASET_DIR):\n",
        "  print('Can not access the training files')\n",
        "  sys.exit('Stopping execution!')\n",
        "\n",
        "if not tf.gfile.Exists(EVAL_ANNOT_DATASET_DIR):\n",
        "  print('Can not access the training files')\n",
        "  sys.exit('Stopping execution!')\n",
        "\n",
        "if not tf.gfile.Exists(TEMP_OUTPUT_DIR):\n",
        "  print('Can not access the temporary directory for storing finetuned models')\n",
        "  sys.exit('Stopping execution!')\n",
        "else:\n",
        "  TEMP_OUTPUT_DIR += USERNAME\n",
        "\n",
        "if not tf.gfile.Exists(os.path.join(BERT_MODEL_DIR,'vocab.txt')):\n",
        "  print('Can not access the Bert model vocabulary file. This file should be located in the Bert model dir')\n",
        "  sys.exit('Stopping execution!')\n",
        "\n",
        "if not tf.gfile.Exists(os.path.join(BERT_MODEL_DIR,'bert_config.json')):\n",
        "  print('Can not access the Bert model config file. This file should be located in the Bert model dir')\n",
        "  sys.exit('Stopping execution!')\n",
        "\n",
        "if not tf.gfile.Exists(BERT_MODEL_FILE):\n",
        "  print('Can not access the Bert model file')\n",
        "  sys.exit('Stopping execution!')\n",
        "\n",
        "if not tf.gfile.Exists(TRAINING_LOG_FILE):\n",
        "  print('The Training Log File used to write training results is not available. Creating one for you.')\n",
        "  f = open(TRAINING_LOG_FILE, 'w+')\n",
        "  head = 'Date,User,Model,Train_Annot_Dataset,Eval_Annot_Dataset,Num_Train_Epochs,Learning_Rate,Max_Seq_Length,Eval_Accuracy,Eval_F_score,Eval_Loss,Loss,Comment\\n'\n",
        "  f.write(head)\n",
        "  f.close()\n",
        "  print('An empty Training Log File has been created in '+TRAINING_LOG_FILE)\n",
        "\n",
        "print ('All necessary files exist!')\n",
        "\n",
        "#Initiation\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=os.path.join(BERT_MODEL_DIR,'vocab.txt'),do_lower_case=LOWER_CASED)\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "processor = vaccineStanceProcessor()\n",
        "\n",
        "label_list = processor.get_labels()\n",
        "\n",
        "# Compute number of train and warmup steps from batch size\n",
        "train_examples = processor.get_train_examples(TRAIN_ANNOT_DATASET_DIR)\n",
        "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "print('There are a total of '+str(len(train_examples))+' training examples in '+TRAIN_ANNOT_DATASET_DIR+'.\\nWe will be training for '+str(NUM_TRAIN_EPOCHS)+' epochs, which means '+str(num_train_steps)+' training steps with a batch size of '+str(TRAIN_BATCH_SIZE)+'.\\n\\n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All necessary files exist!\n",
            "WARNING:tensorflow:From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From bert_repo/run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "There are a total of 6000 training examples in /content/data/cb-annot-en.\n",
            "We will be training for 3 epochs, which means 281 training steps with a batch size of 64.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQysvP_pRShR",
        "colab_type": "text"
      },
      "source": [
        "# Step 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9eJJB0JPsEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Default training and evaluation data loop\n",
        "# estimator_from_checkpoints = model_init()\n",
        "# model_train(estimator_from_checkpoints)\n",
        "# model_eval(estimator_from_checkpoints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TynI54mac88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71c6e4bd-1edf-4223-9876-d02048d69b66"
      },
      "source": [
        "#Experiments\n",
        "iterations = 1\n",
        "import time\n",
        "\n",
        "for _ in range(0,iterations):  \n",
        "  #First experiment\n",
        "  #zeroshot\n",
        "  print(\"\\nStarting first experiment - zeroshot\")\n",
        "  zeroshot_train = ['cb-annot-en']\n",
        "  zeroshot_eval = ['cb-annot-en','cb-annot-en-de','cb-annot-en-es','cb-annot-en-fr','cb-annot-en-pt']\n",
        "\n",
        "  for dataset in zeroshot_train:\n",
        "    TRAIN_ANNOT_DATASET = dataset\n",
        "    TRAIN_ANNOT_DATASET_DIR = os.path.join('/home/per/content/data', dataset)\n",
        "    EXP_NAME = 'zeroshot-'+dataset\n",
        "    print(\"Training \" + EXP_NAME)\n",
        "    estimator_from_checkpoints = model_init()\n",
        "    model_train(estimator_from_checkpoints)\n",
        "  \n",
        "  for dataset in zeroshot_eval:\n",
        "    EVAL_ANNOT_DATASET = dataset\n",
        "    EVAL_ANNOT_DATASET_DIR = os.path.join('/home/per/content/data', dataset)\n",
        "    EXP_NAME = 'zeroshot-'+dataset\n",
        "    print(\"Evaluating \" + EXP_NAME)\n",
        "    model_eval(estimator_from_checkpoints)\n",
        "  \n",
        "  #Second experiment\n",
        "  #translated\n",
        "  print(\"\\nStarting second experiment - translate\")\n",
        "  translated_train = ['cb-annot-en','cb-annot-en-de','cb-annot-en-es','cb-annot-en-fr','cb-annot-en-pt']\n",
        "  translated_eval = ['cb-annot-en','cb-annot-en-de','cb-annot-en-es','cb-annot-en-fr','cb-annot-en-pt']\n",
        "  for idx,dataset in enumerate(translated_train):\n",
        "    TRAIN_ANNOT_DATASET = dataset\n",
        "    TRAIN_ANNOT_DATASET_DIR = os.path.join('/home/per/content/data', dataset)\n",
        "    EXP_NAME = 'translated-'+dataset\n",
        "    print(\"Training \" + EXP_NAME)\n",
        "    estimator_from_checkpoints = model_init()\n",
        "    model_train(estimator_from_checkpoints)\n",
        "    EVAL_ANNOT_DATASET = translated_eval[idx]\n",
        "    EVAL_ANNOT_DATASET_DIR = os.path.join('/home/per/content/data', translated_eval[idx])\n",
        "    EXP_NAME = 'translated-'+translated_eval[idx]\n",
        "    print(\"Evaluating \" + EXP_NAME)\n",
        "    model_eval(estimator_from_checkpoints)\n",
        "    \n",
        "  #Third experiment\n",
        "  #zeroshot\n",
        "  print(\"\\nStarting third experiment - multitranslate\")\n",
        "  multitranslate_train = ['cb-annot-en-de-fr-es']\n",
        "  multitranslate_eval = ['cb-annot-en','cb-annot-en-de','cb-annot-en-es','cb-annot-en-fr','cb-annot-en-pt']\n",
        "  for dataset in multitranslate_train:\n",
        "    TRAIN_ANNOT_DATASET = dataset\n",
        "    TRAIN_ANNOT_DATASET_DIR = os.path.join('/home/per/content/data', dataset)\n",
        "    EXP_NAME = 'multitranslate-'+dataset\n",
        "    print(\"Training \" + EXP_NAME)\n",
        "    estimator_from_checkpoints = model_init()    \n",
        "    model_train(estimator_from_checkpoints)\n",
        "  for dataset in multitranslate_eval:\n",
        "    EVAL_ANNOT_DATASET = dataset\n",
        "    EVAL_ANNOT_DATASET_DIR = os.path.join('/home/per/content/data', dataset)\n",
        "    EXP_NAME = 'multitranslate-'+dataset\n",
        "    print(\"Evaluating \" + EXP_NAME)\n",
        "    model_eval(estimator_from_checkpoints)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting first experiment - zeroshot\n",
            "Training zeroshot-cb-annot-en\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f03ac443158>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://perepublic/finetuned_models/pere', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.32.80.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03a6adcf28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.32.80.50:8470', '_evaluation_master': 'grpc://10.32.80.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f03a84678d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "CommandException: No URLs matched: gs://perepublic/finetuned_models/pere\n",
            "Fine tuning BERT base model normally takes a few minutes. Please wait...\n",
            "WARNING:tensorflow:From bert_repo/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing example 0 of 6000\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-0\n",
            "INFO:tensorflow:tokens: [CLS] \" \" \" Living Good . . Feeling Way Better . . . Me & am ##p ; < @ user > Turn ##ing Up Last Night \" \" # GM ##F x # MM ##R @ Baru Lounge < url > \" [SEP]\n",
            "INFO:tensorflow:input_ids: 101 107 107 107 24371 13073 119 119 68306 15661 34961 119 119 119 11589 111 10392 10410 132 133 137 29115 135 36750 10230 13656 14812 12703 107 107 108 40121 11565 192 108 22283 11273 137 34015 107444 133 88767 135 107 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: neutral (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1\n",
            "INFO:tensorflow:tokens: [CLS] # follow ##dat ##ba ##g dj ##h ##p ##not ##iq # MM ##R < @ user > # F ##DB SP ##IN ##NI ##NG T ##H ##OS ##E 1 & am ##p ; 2 ' s < url > @ I - 95 Bronx [UNK] < url > [SEP]\n",
            "INFO:tensorflow:input_ids: 101 108 28086 17777 10537 10240 71150 10237 10410 32514 35692 108 22283 11273 133 137 29115 135 108 143 51327 22570 27128 52898 34065 157 12396 21793 11259 122 111 10392 10410 132 123 112 187 133 88767 135 137 146 118 11978 60140 100 133 88767 135 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: neutral (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-2\n",
            "INFO:tensorflow:tokens: [CLS] Out ##break of me ##as ##les in Wales linked to fl ##aw ##ed ( and disc ##redi ##ted ) 1998 va ##cci ##ne study . < @ user > < @ user > < url > [SEP]\n",
            "INFO:tensorflow:input_ids: 101 14504 83065 10108 10911 10403 11268 10106 14137 37947 10114 58768 26426 10336 113 10111 27224 110685 11912 114 10363 10321 28217 10238 14687 119 133 137 29115 135 133 137 29115 135 133 88767 135 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: positive (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-3\n",
            "INFO:tensorflow:tokens: [CLS] Instead of twee ##ting about how s ##care ##d you are of E ##bola just drink 2 cup ##s of ble ##ach in the morning and you ' ll be fine . It ' s a natural va ##cci ##ne [SEP]\n",
            "INFO:tensorflow:input_ids: 101 47556 10108 12839 12141 10978 14796 187 22277 10162 13028 10301 10108 142 46260 12820 69423 123 41506 10107 10108 10718 11587 10106 10105 28757 10111 13028 112 22469 10347 13435 119 10377 112 187 169 13409 10321 28217 10238 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: neutral (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-4\n",
            "INFO:tensorflow:tokens: [CLS] LR ##T : Not va ##cci ##nating your children should be e ##qua ##table to child enda ##nger ##ment . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 71203 11090 131 16040 10321 28217 66844 20442 12694 14819 10347 173 32973 30434 10114 18048 28333 18904 10426 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: positive (id = 0)\n",
            "***** Started training at 2020-02-06 15:29:23.010917 *****\n",
            "  Num examples = 6000\n",
            "  Batch size = 64\n",
            "  Train steps = 281\n",
            "  Epochs = 3\n",
            "INFO:tensorflow:  Num steps = 281\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.32.80.50:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 9056964511981067859)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 16419117274771192929)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 15293778589907173645)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11363403226778945391)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 16541929340818009114)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13779756758022404792)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3598447114234383465)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9756882873676041476)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4215090844268192741)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 18231005442920781020)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12578579154270239786)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (8, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (8, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (8,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (8, 128)\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From bert_repo/run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (119547, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (3, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (3,)\n",
            "WARNING:tensorflow:From bert_repo/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From bert_repo/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From bert_repo/run_classifier.py:656: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From bert_repo/run_classifier.py:657: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}